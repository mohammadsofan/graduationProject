{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1947264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.applications import DenseNet169\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Dropout, BatchNormalization, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, cohen_kappa_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import roc_auc_score, cohen_kappa_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca630d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "IMG_SIZE = (320, 320)  \n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 20\n",
    "DATA_PATH = \"../MURA-v1.1\"\n",
    "TRAIN_PATH = DATA_PATH + \"/train_labeled_studies.csv\"\n",
    "VALID_PATH = DATA_PATH + \"/valid_labeled_studies.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e684e419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "def load_data(csv_path):\n",
    "    df = pd.read_csv(csv_path, names=['Path', 'Label'], header=None)\n",
    "    image_paths, labels = [], []\n",
    "    base_dir = \"../\"  # Root dataset directory\n",
    "    for _, row in df.iterrows():\n",
    "        study_path = os.path.join(base_dir, row[\"Path\"])\n",
    "        label = row[\"Label\"]\n",
    "        for image_file in os.listdir(study_path):\n",
    "            image_path = os.path.join(study_path, image_file)\n",
    "            if image_path.endswith(\".png\") and not image_file.startswith(\"._\"):\n",
    "                image_paths.append(image_path)\n",
    "                labels.append(label)\n",
    "    return np.array(image_paths), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c075965",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths, train_labels = load_data(TRAIN_PATH)\n",
    "valid_image_paths, valid_labels = load_data(VALID_PATH)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_image_paths, train_labels, test_size=0.1, stratify=train_labels, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef6984ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 0.40406976744186046, 1: 0.5959302325581395}\n"
     ]
    }
   ],
   "source": [
    "# Convert labels into a Pandas Series\n",
    "todf = pd.Series(train_labels)\n",
    "\n",
    "# Count occurrences of each class\n",
    "class_counts = todf.value_counts().to_dict()\n",
    "\n",
    "# Get the counts (handle cases where labels might be missing)\n",
    "NormalCount = class_counts.get(0, 0)  # Normal (0)\n",
    "AbnormalCount = class_counts.get(1, 0)  # Abnormal (1)\n",
    "\n",
    "# Compute class weights\n",
    "w1 = NormalCount / (NormalCount + AbnormalCount)  # Weight for class 0\n",
    "w2 = AbnormalCount / (NormalCount + AbnormalCount)  # Weight for class 1\n",
    "\n",
    "class_weights = {0: w2, 1: w1}  # More weight to minority class\n",
    "print(\"Class Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23cc09d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "229fcad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MURADataGenerator(Sequence):\n",
    "    def __init__(self, image_paths, labels, class_weights, batch_size=BATCH_SIZE, img_size=IMG_SIZE, augment=False, shuffle=True):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.class_weights = class_weights  # Store class weights\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.augment = augment\n",
    "        self.shuffle = shuffle\n",
    "        self.datagen = train_datagen if augment else None\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_paths = self.image_paths[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_labels = self.labels[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        \n",
    "        # Generate images and labels\n",
    "        X, y = self.__data_generation(batch_paths, batch_labels)\n",
    "        \n",
    "        # Generate sample weights based on labels\n",
    "        sample_weights = np.array([self.class_weights[label] for label in batch_labels])\n",
    "        \n",
    "        return X, y, sample_weights  # Now returning (X, y, sample_weights)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            temp = list(zip(self.image_paths, self.labels))\n",
    "            np.random.shuffle(temp)\n",
    "            self.image_paths, self.labels = zip(*temp)\n",
    "    \n",
    "    def __data_generation(self, batch_paths, batch_labels):\n",
    "        images = []\n",
    "        for path in batch_paths:\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, self.img_size)\n",
    "            img = img / 255.0  # Normalize\n",
    "            img = np.stack([img] * 3, axis=-1)  # Convert to 3 channels\n",
    "            if self.augment:\n",
    "                img = self.datagen.random_transform(img)\n",
    "            images.append(img)\n",
    "        return np.array(images).reshape(-1, *self.img_size, 3), np.array(batch_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8ec8e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators\n",
    "train_generator = MURADataGenerator(X_train, y_train,class_weights, augment=True)\n",
    "valid_generator = MURADataGenerator(valid_image_paths, valid_labels,class_weights, augment=False, shuffle=False)\n",
    "test_generator = MURADataGenerator(X_test, y_test,class_weights, augment=False, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7966255",
   "metadata": {},
   "source": [
    "## image level performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a052aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def test(pred,y_test,th):# Ensure predictions are flattened\n",
    "    predictions = pred.flatten()\n",
    "    predictions = (predictions > th).astype(int)\n",
    "    # Convert to NumPy arrays\n",
    "    y_test = np.array(y_test).astype(int)\n",
    "    predictions = np.array(predictions).astype(int)\n",
    "\n",
    "    # Count correct and incorrect predictions\n",
    "    true_positives = np.sum((predictions == 1) & (y_test == 1))\n",
    "    true_negatives = np.sum((predictions == 0) & (y_test == 0))\n",
    "    false_positives = np.sum((predictions == 1) & (y_test == 0))\n",
    "    false_negatives = np.sum((predictions == 0) & (y_test == 1))\n",
    "\n",
    "    # Print results\n",
    "    print(f\"True Positives: {true_positives}\")\n",
    "    print(f\"True Negatives: {true_negatives}\")\n",
    "    print(f\"False Positives: {false_positives}\")\n",
    "    print(f\"False Negatives: {false_negatives}\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = (true_positives + true_negatives) / len(y_test)\n",
    "    print(f\"Calculated Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    print(f\"F1-Score: {f1_score:.2f}\")\n",
    "    from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "    # Compute Cohen's Kappa\n",
    "    kappa = cohen_kappa_score(y_test, predictions)\n",
    "    print(f\"Cohen's Kappa: {kappa:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7915ef8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86a8a1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "/home/mohammad/.local/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "2025-03-24 00:55:26.919781: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.79GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-03-24 00:55:26.998325: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.33GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-03-24 00:55:27.669718: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-03-24 00:55:28.951602: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.74GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m461/461\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 83ms/step\n",
      "True Positives: 1122\n",
      "True Negatives: 1841\n",
      "False Positives: 353\n",
      "False Negatives: 365\n",
      "Calculated Accuracy: 80.49%\n",
      "Precision: 0.76\n",
      "Recall: 0.75\n",
      "F1-Score: 0.76\n",
      "Cohen's Kappa: 0.59\n"
     ]
    }
   ],
   "source": [
    "model=load_model(\"model_epoch09_val_loss0.2801.h5\")\n",
    "pred1=model.predict(test_generator)\n",
    "test(pred1,y_test,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d13f02d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m461/461\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 78ms/step\n",
      "True Positives: 1198\n",
      "True Negatives: 1644\n",
      "False Positives: 550\n",
      "False Negatives: 289\n",
      "Calculated Accuracy: 77.21%\n",
      "Precision: 0.69\n",
      "Recall: 0.81\n",
      "F1-Score: 0.74\n",
      "Cohen's Kappa: 0.54\n"
     ]
    }
   ],
   "source": [
    "model=load_model(\"../denseModel5/model2_dense.h5\")\n",
    "pred2=model.predict(test_generator)\n",
    "test(pred2,y_test,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff891f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742770052.555883   22133 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4474 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "/home/mohammad/.local/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742770057.091696   22179 service.cc:148] XLA service 0x7831f4002110 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1742770057.091712   22179 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce GTX 1660, Compute Capability 7.5\n",
      "2025-03-24 00:47:37.165305: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1742770057.886121   22179 cuda_dnn.cc:529] Loaded cuDNN version 90701\n",
      "2025-03-24 00:47:38.423102: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[8,64,80,80]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,64,80,80]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-03-24 00:47:38.667567: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[8,128,40,40]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,128,40,40]{3,2,1,0}, f32[128,128,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-03-24 00:47:38.902665: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[8,256,20,20]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,256,20,20]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-03-24 00:47:39.142701: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[8,512,10,10]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,512,10,10]{3,2,1,0}, f32[512,512,3,3]{3,2,1,0}, f32[512]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  2/461\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 89ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742770060.442903   22179 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m460/461\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 00:48:21.930051: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[1,64,80,80]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,64,80,80]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-03-24 00:48:22.062402: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[1,128,40,40]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,128,40,40]{3,2,1,0}, f32[128,128,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-03-24 00:48:22.217281: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[1,256,20,20]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,256,20,20]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-03-24 00:48:22.390832: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[1,512,10,10]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,512,10,10]{3,2,1,0}, f32[512,512,3,3]{3,2,1,0}, f32[512]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m461/461\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 94ms/step\n",
      "True Positives: 1021\n",
      "True Negatives: 1990\n",
      "False Positives: 204\n",
      "False Negatives: 466\n",
      "Calculated Accuracy: 81.80%\n",
      "Precision: 0.83\n",
      "Recall: 0.69\n",
      "F1-Score: 0.75\n",
      "Cohen's Kappa: 0.61\n"
     ]
    }
   ],
   "source": [
    "model=load_model(\"resnet101_model_epoch19_val_loss0.2636.h5\")\n",
    "pred3=model.predict(test_generator)\n",
    "test(pred3,y_test,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e007db26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m461/461\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 92ms/step\n",
      "True Positives: 1185\n",
      "True Negatives: 1776\n",
      "False Positives: 418\n",
      "False Negatives: 302\n",
      "Calculated Accuracy: 80.44%\n",
      "Precision: 0.74\n",
      "Recall: 0.80\n",
      "F1-Score: 0.77\n",
      "Cohen's Kappa: 0.60\n"
     ]
    }
   ],
   "source": [
    "model=load_model(\"resnet101_model2.h5\")\n",
    "pred4=model.predict(test_generator)\n",
    "test(pred4,y_test,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7d4ee9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6297519]\n",
      "[0.6769962]\n",
      "[0.88547075]\n",
      "[0.8647019]\n",
      "[0.7642302]\n",
      "1\n",
      "True Positives: 1160\n",
      "True Negatives: 1870\n",
      "False Positives: 324\n",
      "False Negatives: 327\n",
      "Calculated Accuracy: 82.31%\n",
      "Precision: 0.78\n",
      "Recall: 0.78\n",
      "F1-Score: 0.78\n",
      "Cohen's Kappa: 0.63\n"
     ]
    }
   ],
   "source": [
    "# Compute the mean prediction\n",
    "ensemble_pred = (pred1 + pred2 + pred3 + pred4) / 4\n",
    "c=555\n",
    "print(pred1[c])\n",
    "print(pred2[c])\n",
    "print(pred3[c])\n",
    "print(pred4[c])\n",
    "print(ensemble_pred[c])\n",
    "print(y_test[c])\n",
    "\n",
    "# Evaluate the ensemble predictions\n",
    "test(ensemble_pred, y_test,0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2340206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 1200\n",
      "True Negatives: 1787\n",
      "False Positives: 407\n",
      "False Negatives: 287\n",
      "Calculated Accuracy: 81.15%\n",
      "Precision: 0.75\n",
      "Recall: 0.81\n",
      "F1-Score: 0.78\n",
      "Cohen's Kappa: 0.61\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the ensemble predictions\n",
    "test(ensemble_pred, y_test,0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e214e4da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
